{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b980f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa320b9",
   "metadata": {},
   "source": [
    "In here firstly we load our data and then we plan on what to do next as to what out expectations from the data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dddfc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unlabeled = pd.read_csv(\"tweets_21.csv\")\n",
    "df_labeled = pd.read_csv(\"tweets_labeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2841f9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1344798002490314752</td>\n",
       "      <td>Kardesim (12) sevdigi cocuga 00:00 da ilan-i a...</td>\n",
       "      <td>2021-01-01 03:10:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1344799527673470977</td>\n",
       "      <td>Bu yılbaşı da saat tam 00:00'da swni seviyorum...</td>\n",
       "      <td>2021-01-01 03:16:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1344799907719348226</td>\n",
       "      <td>tam 00.00da naptınız ben her yıl tam bu vakit ...</td>\n",
       "      <td>2021-01-01 03:17:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1344800782802165762</td>\n",
       "      <td>00:00'da havai fişek gösterisi yapıldı tam dib...</td>\n",
       "      <td>2021-01-01 03:21:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1344805589990453249</td>\n",
       "      <td>31 aralık saat 00.00 da yeni yılımızı kutlayan...</td>\n",
       "      <td>2021-01-01 03:40:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                              tweet  \\\n",
       "0  1344798002490314752  Kardesim (12) sevdigi cocuga 00:00 da ilan-i a...   \n",
       "1  1344799527673470977  Bu yılbaşı da saat tam 00:00'da swni seviyorum...   \n",
       "2  1344799907719348226  tam 00.00da naptınız ben her yıl tam bu vakit ...   \n",
       "3  1344800782802165762  00:00'da havai fişek gösterisi yapıldı tam dib...   \n",
       "4  1344805589990453249  31 aralık saat 00.00 da yeni yılımızı kutlayan...   \n",
       "\n",
       "                  date  \n",
       "0  2021-01-01 03:10:03  \n",
       "1  2021-01-01 03:16:07  \n",
       "2  2021-01-01 03:17:37  \n",
       "3  2021-01-01 03:21:06  \n",
       "4  2021-01-01 03:40:12  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unlabeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6268a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1606767075984375808</td>\n",
       "      <td>Berk Ali (kedim) seni çok özledim. Ölmek için ...</td>\n",
       "      <td>2022-12-24 21:41:37+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1537178207677448193</td>\n",
       "      <td>Yani, öylesine ciddiye alacaksın ki yaşamayı, ...</td>\n",
       "      <td>2022-06-15 21:00:18+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1536458790802972673</td>\n",
       "      <td>saçlarının gölgesinde\\nölmek ne güzeldi</td>\n",
       "      <td>2022-06-13 21:21:36+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1495413883166760960</td>\n",
       "      <td>Öyle güzel baktın ki, gözlerime\\nsevmek değil ...</td>\n",
       "      <td>2022-02-20 15:03:47+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1490420667614904334</td>\n",
       "      <td>sevmek biri için ölmek değil her şeye rağmen y...</td>\n",
       "      <td>2022-02-06 20:22:32+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                              tweet  \\\n",
       "0  1606767075984375808  Berk Ali (kedim) seni çok özledim. Ölmek için ...   \n",
       "1  1537178207677448193  Yani, öylesine ciddiye alacaksın ki yaşamayı, ...   \n",
       "2  1536458790802972673            saçlarının gölgesinde\\nölmek ne güzeldi   \n",
       "3  1495413883166760960  Öyle güzel baktın ki, gözlerime\\nsevmek değil ...   \n",
       "4  1490420667614904334  sevmek biri için ölmek değil her şeye rağmen y...   \n",
       "\n",
       "                        date  label  \n",
       "0  2022-12-24 21:41:37+00:00      1  \n",
       "1  2022-06-15 21:00:18+00:00      1  \n",
       "2  2022-06-13 21:21:36+00:00      1  \n",
       "3  2022-02-20 15:03:47+00:00      1  \n",
       "4  2022-02-06 20:22:32+00:00      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bb97781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13272 entries, 0 to 13271\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   tweet_id  13272 non-null  int64 \n",
      " 1   tweet     13272 non-null  object\n",
      " 2   date      13272 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 311.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_unlabeled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "485a0642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13272 entries, 0 to 13271\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   tweet_id  13272 non-null  int64 \n",
      " 1   tweet     13272 non-null  object\n",
      " 2   date      13272 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 311.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_unlabeled.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac82903",
   "metadata": {},
   "source": [
    "## Data Cleaning and Future Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c25ac29",
   "metadata": {},
   "source": [
    "Now we do a cleaning process. This celaning in the fature will assure out models to be optimized as well as to make EDA easy and detailed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018fe75c",
   "metadata": {},
   "source": [
    "#### Cleaning\n",
    "1. localize and seperate \"date\" column for EDA\n",
    "2. change all tweets to lower case\n",
    "3. emoticon classification\n",
    "4. replace punctuations with space \n",
    "5. replace special characters and number with space\n",
    "6. remove tweets with one word\n",
    "7. tokenize the tweet column\n",
    "8. remove stop words from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caaf1d2",
   "metadata": {},
   "source": [
    "##### 1. localize and seperate \"date\" column for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ecdaac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id    0\n",
       "tweet       1\n",
       "date        0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35570ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id    0\n",
       "tweet       0\n",
       "date        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unlabeled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d75c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled[\"date\"] = pd.to_datetime(df_labeled[\"date\"])\n",
    "df_labeled['date'] = df_labeled['date'].dt.tz_localize(None)\n",
    "df_unlabeled[\"date\"] = pd.to_datetime(df_unlabeled[\"date\"])\n",
    "df_unlabeled['date'] = df_unlabeled['date'].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c93c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled[\"month\"] = df_labeled[\"date\"].dt.month_name()\n",
    "df_unlabeled[\"month\"] = df_unlabeled[\"date\"].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "379eb3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_month_names(df, column_name):\n",
    "    month_translation = {\n",
    "        \"December\": \"Aralık\",\n",
    "        \"January\": \"Ocak\",\n",
    "        \"February\": \"Şubat\",\n",
    "        \"March\": \"Mart\",\n",
    "        \"April\": \"Nisan\",\n",
    "        \"May\": \"Mayıs\",\n",
    "        \"June\": \"Haziran\",\n",
    "        \"July\": \"Temmuz\",\n",
    "        \"August\": \"Ağustos\",\n",
    "        \"September\": \"Eylül\",\n",
    "        \"October\": \"Ekim\",\n",
    "        \"November\": \"Kasım\"\n",
    "    }\n",
    "    df[column_name] = df[column_name].replace(month_translation)\n",
    "    return df\n",
    "\n",
    "df_labeled = replace_month_names(df_labeled, 'month')\n",
    "df_unlabeled = replace_month_names(df_unlabeled, 'month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4da25c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = {\"Ocak\": \"Kış\",\n",
    "           \"Şubat\": \"Kış\",\n",
    "           \"Mart\": \"İlkbahar\",\n",
    "           \"Nisan\": \"İlkbahar\",\n",
    "           \"Mayıs\": \"İlkbahar\",\n",
    "           \"Haziran\": \"Yaz\",\n",
    "           \"Temmuz\": \"Yaz\",\n",
    "           \"Ağustos\": \"Yaz\",\n",
    "           \"Eylül\": \"Sonbahar\",\n",
    "           \"Ekim\": \"Sonbahar\",\n",
    "           \"Kasım\": \"Sonbahar\",\n",
    "           \"Aralık\": \"Kış\"}\n",
    "df_labeled['seasons'] = df_labeled['month'].map(seasons)\n",
    "df_unlabeled['seasons'] = df_unlabeled['month'].map(seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9605628",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled = df_labeled.dropna()\n",
    "df_unlabeled = df_unlabeled.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ba4b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled[\"days\"] = [date.strftime('%A') for date in df_labeled[\"date\"]]\n",
    "df_unlabeled[\"days\"] = [date.strftime('%A') for date in df_unlabeled[\"date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0ff2eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_day_names(df,column_name):\n",
    "    day_translation = {\"Monday\" : \"Pazartesi\",\n",
    "                                 \"Tuesday\" : \"Salı\",\n",
    "                                 \"Wednesday\" : \"Çarşamba\",\n",
    "                                 \"Thursday\": \"Perşembe\",\n",
    "                                 \"Friday\" : \"Cuma\",\n",
    "                                 \"Saturday\" : \"Cumartesi\",\n",
    "                                 \"Sunday\": \"Pazar\"}\n",
    "    df[column_name] = df[column_name].replace(day_translation)\n",
    "    return df\n",
    "\n",
    "df_labeled = replace_day_names(df_labeled,\"days\")\n",
    "df_unlabeled = replace_day_names(df_unlabeled,\"days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c39d5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled['hour'] = df_labeled['date'].dt.hour\n",
    "df_labeled['4hour_interval'] = (df_labeled['hour'] // 2) * 2\n",
    "interval = {0: '0-2',\n",
    "            2: '2-4',\n",
    "            4: '4-6',\n",
    "            6: '6-8',\n",
    "            8: '8-10',\n",
    "            10: '10-12',\n",
    "            12: '12-14',\n",
    "            14: '14-16',\n",
    "            16: '16-18',\n",
    "            18: '18-20',\n",
    "            20: '20-22',\n",
    "            22: '22-24'\n",
    "            }\n",
    "\n",
    "df_unlabeled['hour'] = df_unlabeled['date'].dt.hour\n",
    "df_unlabeled['4hour_interval'] = (df_unlabeled['hour'] // 2) * 2\n",
    "interval = {0: '0-2',\n",
    "            2: '2-4',\n",
    "            4: '4-6',\n",
    "            6: '6-8',\n",
    "            8: '8-10',\n",
    "            10: '10-12',\n",
    "            12: '12-14',\n",
    "            14: '14-16',\n",
    "            16: '16-18',\n",
    "            18: '18-20',\n",
    "            20: '20-22',\n",
    "            22: '22-24'\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "055f337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_hour_interval(df,column_name):\n",
    "    hour_tranlation = { \"0-2\": \"22-02\",\n",
    "                        \"22-24\": \"22-02\",\n",
    "                        \"2-4\": \"02-06\",\n",
    "                        \"4-6\": \"02-06\",\n",
    "                        \"6-8\": \"06-10\",\n",
    "                        \"8-10\": \"06-10\",\n",
    "                        \"10-12\": \"10-14\",\n",
    "                        \"12-14\": \"10-14\",\n",
    "                        \"14-16\": \"14-18\",\n",
    "                        \"16-18\": \"14-18\",\n",
    "                        \"18-20\": \"18-22\",\n",
    "                        \"20-22\": \"18-22\"}\n",
    "    df[column_name] = df[column_name].replace(hour_tranlation)\n",
    "    return df\n",
    "\n",
    "df_labeled = replace_hour_interval(df_labeled,\"4hour_interval\")\n",
    "df_unlabeled = replace_hour_interval(df_unlabeled,\"4hour_interval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b56d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled.drop([\"4hour_interval\", \"hour\"], axis=1, inplace=True)\n",
    "df_unlabeled.drop([\"4hour_interval\", \"hour\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc3b2f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>month</th>\n",
       "      <th>seasons</th>\n",
       "      <th>days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1606767075984375808</td>\n",
       "      <td>Berk Ali (kedim) seni çok özledim. Ölmek için ...</td>\n",
       "      <td>2022-12-24 21:41:37</td>\n",
       "      <td>1</td>\n",
       "      <td>Aralık</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cumartesi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1537178207677448193</td>\n",
       "      <td>Yani, öylesine ciddiye alacaksın ki yaşamayı, ...</td>\n",
       "      <td>2022-06-15 21:00:18</td>\n",
       "      <td>1</td>\n",
       "      <td>Haziran</td>\n",
       "      <td>Yaz</td>\n",
       "      <td>Çarşamba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1536458790802972673</td>\n",
       "      <td>saçlarının gölgesinde\\nölmek ne güzeldi</td>\n",
       "      <td>2022-06-13 21:21:36</td>\n",
       "      <td>1</td>\n",
       "      <td>Haziran</td>\n",
       "      <td>Yaz</td>\n",
       "      <td>Pazartesi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1495413883166760960</td>\n",
       "      <td>Öyle güzel baktın ki, gözlerime\\nsevmek değil ...</td>\n",
       "      <td>2022-02-20 15:03:47</td>\n",
       "      <td>1</td>\n",
       "      <td>Şubat</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Pazar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1490420667614904334</td>\n",
       "      <td>sevmek biri için ölmek değil her şeye rağmen y...</td>\n",
       "      <td>2022-02-06 20:22:32</td>\n",
       "      <td>1</td>\n",
       "      <td>Şubat</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Pazar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                              tweet  \\\n",
       "0  1606767075984375808  Berk Ali (kedim) seni çok özledim. Ölmek için ...   \n",
       "1  1537178207677448193  Yani, öylesine ciddiye alacaksın ki yaşamayı, ...   \n",
       "2  1536458790802972673            saçlarının gölgesinde\\nölmek ne güzeldi   \n",
       "3  1495413883166760960  Öyle güzel baktın ki, gözlerime\\nsevmek değil ...   \n",
       "4  1490420667614904334  sevmek biri için ölmek değil her şeye rağmen y...   \n",
       "\n",
       "                 date  label    month seasons       days  \n",
       "0 2022-12-24 21:41:37      1   Aralık     Kış  Cumartesi  \n",
       "1 2022-06-15 21:00:18      1  Haziran     Yaz   Çarşamba  \n",
       "2 2022-06-13 21:21:36      1  Haziran     Yaz  Pazartesi  \n",
       "3 2022-02-20 15:03:47      1    Şubat     Kış      Pazar  \n",
       "4 2022-02-06 20:22:32      1    Şubat     Kış      Pazar  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ceded06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>seasons</th>\n",
       "      <th>days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1344798002490314752</td>\n",
       "      <td>Kardesim (12) sevdigi cocuga 00:00 da ilan-i a...</td>\n",
       "      <td>2021-01-01 03:10:03</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1344799527673470977</td>\n",
       "      <td>Bu yılbaşı da saat tam 00:00'da swni seviyorum...</td>\n",
       "      <td>2021-01-01 03:16:07</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1344799907719348226</td>\n",
       "      <td>tam 00.00da naptınız ben her yıl tam bu vakit ...</td>\n",
       "      <td>2021-01-01 03:17:37</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1344800782802165762</td>\n",
       "      <td>00:00'da havai fişek gösterisi yapıldı tam dib...</td>\n",
       "      <td>2021-01-01 03:21:06</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1344805589990453249</td>\n",
       "      <td>31 aralık saat 00.00 da yeni yılımızı kutlayan...</td>\n",
       "      <td>2021-01-01 03:40:12</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                              tweet  \\\n",
       "0  1344798002490314752  Kardesim (12) sevdigi cocuga 00:00 da ilan-i a...   \n",
       "1  1344799527673470977  Bu yılbaşı da saat tam 00:00'da swni seviyorum...   \n",
       "2  1344799907719348226  tam 00.00da naptınız ben her yıl tam bu vakit ...   \n",
       "3  1344800782802165762  00:00'da havai fişek gösterisi yapıldı tam dib...   \n",
       "4  1344805589990453249  31 aralık saat 00.00 da yeni yılımızı kutlayan...   \n",
       "\n",
       "                 date month seasons  days  \n",
       "0 2021-01-01 03:10:03  Ocak     Kış  Cuma  \n",
       "1 2021-01-01 03:16:07  Ocak     Kış  Cuma  \n",
       "2 2021-01-01 03:17:37  Ocak     Kış  Cuma  \n",
       "3 2021-01-01 03:21:06  Ocak     Kış  Cuma  \n",
       "4 2021-01-01 03:40:12  Ocak     Kış  Cuma  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unlabeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "556e8419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>seasons</th>\n",
       "      <th>days</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1344798002490314752</td>\n",
       "      <td>Kardesim (12) sevdigi cocuga 00:00 da ilan-i a...</td>\n",
       "      <td>2021-01-01 03:10:03</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1344799527673470977</td>\n",
       "      <td>Bu yılbaşı da saat tam 00:00'da swni seviyorum...</td>\n",
       "      <td>2021-01-01 03:16:07</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1344799907719348226</td>\n",
       "      <td>tam 00.00da naptınız ben her yıl tam bu vakit ...</td>\n",
       "      <td>2021-01-01 03:17:37</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1344800782802165762</td>\n",
       "      <td>00:00'da havai fişek gösterisi yapıldı tam dib...</td>\n",
       "      <td>2021-01-01 03:21:06</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1344805589990453249</td>\n",
       "      <td>31 aralık saat 00.00 da yeni yılımızı kutlayan...</td>\n",
       "      <td>2021-01-01 03:40:12</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                              tweet  \\\n",
       "0  1344798002490314752  Kardesim (12) sevdigi cocuga 00:00 da ilan-i a...   \n",
       "1  1344799527673470977  Bu yılbaşı da saat tam 00:00'da swni seviyorum...   \n",
       "2  1344799907719348226  tam 00.00da naptınız ben her yıl tam bu vakit ...   \n",
       "3  1344800782802165762  00:00'da havai fişek gösterisi yapıldı tam dib...   \n",
       "4  1344805589990453249  31 aralık saat 00.00 da yeni yılımızı kutlayan...   \n",
       "\n",
       "                 date month seasons  days  label  \n",
       "0 2021-01-01 03:10:03  Ocak     Kış  Cuma    NaN  \n",
       "1 2021-01-01 03:16:07  Ocak     Kış  Cuma    NaN  \n",
       "2 2021-01-01 03:17:37  Ocak     Kış  Cuma    NaN  \n",
       "3 2021-01-01 03:21:06  Ocak     Kış  Cuma    NaN  \n",
       "4 2021-01-01 03:40:12  Ocak     Kış  Cuma    NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.concat([df_unlabeled,df_labeled,], ignore_index = True)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f4457cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26231 entries, 0 to 26230\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   tweet_id  26231 non-null  int64         \n",
      " 1   tweet     26231 non-null  object        \n",
      " 2   date      26231 non-null  datetime64[ns]\n",
      " 3   month     26231 non-null  object        \n",
      " 4   seasons   26231 non-null  object        \n",
      " 5   days      26231 non-null  object        \n",
      " 6   label     12959 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fef2f50",
   "metadata": {},
   "source": [
    "##### 2. change all tweets to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11598ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"tweet\"] = combined_df[\"tweet\"].astype(str)\n",
    "df_unlabeled[\"tweet\"] = df_unlabeled[\"tweet\"].astype(str)\n",
    "df_labeled[\"tweet\"] = df_labeled[\"tweet\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16223c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"tweet\"] = combined_df[\"tweet\"].apply(lambda str1: str1.lower())\n",
    "df_unlabeled[\"tweet\"] = df_unlabeled[\"tweet\"].apply(lambda str2: str2.lower())\n",
    "df_labeled[\"tweet\"] = df_labeled[\"tweet\"].apply(lambda str3: str3.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561334e2",
   "metadata": {},
   "source": [
    "##### 3. emoticon classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9df0505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_dict = {\n",
    "\":)\": \"happy\",\n",
    "\":‑)\": \"happy\",\n",
    "\":-]\": \"happy\",\n",
    "\":-3\": \"happy\",\n",
    "\":->\": \"happy\",\n",
    "\"8-)\": \"happy\",\n",
    "\":-}\": \"happy\",\n",
    "\":o)\": \"happy\",\n",
    "\":c)\": \"happy\",\n",
    "\":^)\": \"happy\",\n",
    "\"=]\": \"happy\",\n",
    "\"=)\": \"happy\",\n",
    "\"<3\": \"happy\",\n",
    "\":-(\": \"sad\",\n",
    "\":(\": \"sad\",\n",
    "\":c\": \"sad\",\n",
    "\":<\": \"sad\",\n",
    "\":[\": \"sad\",\n",
    "\">:[\": \"sad\",\n",
    "\":{\": \"sad\",\n",
    "\">:(\": \"sad\",\n",
    "\":-c\": \"sad\",\n",
    "\":-< \": \"sad\",\n",
    "\":-[\": \"sad\",\n",
    "\":-||\": \"sad\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0aecca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(text, dictionary):\n",
    "    for word in text.split():\n",
    "        if word.lower() in dictionary:\n",
    "            if word.lower() in text.split():\n",
    "                text = text.replace(word, dictionary[word.lower()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8dbbe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"tweet\"] = combined_df[\"tweet\"].apply(lambda x: classification(x,emoticon_dict))\n",
    "df_unlabeled[\"tweet\"] = df_unlabeled[\"tweet\"].apply(lambda x: classification(x,emoticon_dict))\n",
    "df_labeled[\"tweet\"] = df_labeled[\"tweet\"].apply(lambda x: classification(x,emoticon_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a187165",
   "metadata": {},
   "source": [
    "##### 4. replace punctuations with space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d54c3ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"tweet\"] = combined_df[\"tweet\"].apply(lambda x: re.sub(r'[^\\w\\s]',' ',x))\n",
    "df_unlabeled[\"tweet\"] = df_unlabeled[\"tweet\"].apply(lambda x: re.sub(r'[^\\w\\s]',' ',x))\n",
    "df_labeled[\"tweet\"] = df_labeled[\"tweet\"].apply(lambda x: re.sub(r'[^\\w\\s]',' ',x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93f1dd2",
   "metadata": {},
   "source": [
    "##### 5. replace special characters and number with space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50aa878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"tweet\"] = combined_df[\"tweet\"].apply(lambda x: re.sub(r'[^a-zA-ZğüşıöçĞÜŞİÖÇ\\s]|\\d+',' ',x))\n",
    "df_unlabeled[\"tweet\"] = df_unlabeled[\"tweet\"].apply(lambda x: re.sub(r'[^a-zA-ZğüşıöçĞÜŞİÖÇ\\s]|\\d+',' ',x))\n",
    "df_labeled[\"tweet\"] = df_labeled[\"tweet\"].apply(lambda x: re.sub(r'[^a-zA-ZğüşıöçĞÜŞİÖÇ\\s]|\\d+',' ',x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443e62e4",
   "metadata": {},
   "source": [
    "##### 6. tokenize the tweet column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a631de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"tweet_token\"] = combined_df[\"tweet\"].apply(lambda x: word_tokenize(x))\n",
    "df_unlabeled[\"tweet_token\"] = df_unlabeled[\"tweet\"].apply(lambda x: word_tokenize(x))\n",
    "df_labeled[\"tweet_token\"] = df_labeled[\"tweet\"].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c970532b",
   "metadata": {},
   "source": [
    "#### can be used for the same job\n",
    "def tokenize(df,column):\n",
    "\n",
    "    for i,row in df.iterrows():\n",
    "        text = row[column]\n",
    "        text_token = word_tokenize(text)\n",
    "    return df\n",
    "    \n",
    "combined_df[\"tweet_token\"] = combined_df[\"tweet_token\"]\n",
    "tokenize(combined_df,\"tweet_token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907bdcef",
   "metadata": {},
   "source": [
    "##### 7. remove tweets with one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecd0abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"tweet\"] = combined_df[\"tweet\"].apply(lambda x: \"\".join([w for w in x.split() if len(w)>1]))\n",
    "df_unlabeled[\"tweet\"] = df_unlabeled[\"tweet\"].apply(lambda x: \"\".join([w for w in x.split() if len(w)>1]))\n",
    "df_labeled[\"tweet\"] = df_labeled[\"tweet\"].apply(lambda x: \"\".join([w for w in x.split() if len(w)>1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "572734f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"tweet_token\"] = combined_df[\"tweet_token\"].apply(lambda tokens: [token for token in tokens if len(token) > 1])\n",
    "df_unlabeled[\"tweet_token\"] = df_unlabeled[\"tweet_token\"].apply(lambda tokens: [token for token in tokens if len(token) > 1])\n",
    "df_labeled[\"tweet_token\"] = df_labeled[\"tweet_token\"].apply(lambda tokens: [token for token in tokens if len(token) > 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d924c64",
   "metadata": {},
   "source": [
    "###### can be used for the same job\n",
    "def filter_single_chars(tokens):\n",
    "    return [token for token in tokens if len(token) > 1]\n",
    "\n",
    "combined_df[\"tweet_token\"] = combined_df[\"tweet_token\"].apply(filter_single_chars)\n",
    "\n",
    "print(combined_df[\"tweet_token\"].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98d0a2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>seasons</th>\n",
       "      <th>days</th>\n",
       "      <th>tweet_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1344798002490314752</td>\n",
       "      <td>kardesimsevdigicocugadailanasketmiscocuksimdiy...</td>\n",
       "      <td>2021-01-01 03:10:03</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "      <td>[kardesim, sevdigi, cocuga, da, ilan, ask, etm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1344799527673470977</td>\n",
       "      <td>buyılbaşıdasaattamdaswniseviyorummesajıgelmedi</td>\n",
       "      <td>2021-01-01 03:16:07</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "      <td>[bu, yılbaşı, da, saat, tam, da, swni, seviyor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1344799907719348226</td>\n",
       "      <td>tamdanaptınızbenheryıltambuvakitdinlediğimşark...</td>\n",
       "      <td>2021-01-01 03:17:37</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "      <td>[tam, da, naptınız, ben, her, yıl, tam, bu, va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1344800782802165762</td>\n",
       "      <td>dahavaifişekgösterisiyapıldıtamdibimizdeancakk...</td>\n",
       "      <td>2021-01-01 03:21:06</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "      <td>[da, havai, fişek, gösterisi, yapıldı, tam, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1344805589990453249</td>\n",
       "      <td>aralıksaatdayeniyılımızıkutlayanbirisiyineolma...</td>\n",
       "      <td>2021-01-01 03:40:12</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "      <td>[aralık, saat, da, yeni, yılımızı, kutlayan, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                              tweet  \\\n",
       "0  1344798002490314752  kardesimsevdigicocugadailanasketmiscocuksimdiy...   \n",
       "1  1344799527673470977     buyılbaşıdasaattamdaswniseviyorummesajıgelmedi   \n",
       "2  1344799907719348226  tamdanaptınızbenheryıltambuvakitdinlediğimşark...   \n",
       "3  1344800782802165762  dahavaifişekgösterisiyapıldıtamdibimizdeancakk...   \n",
       "4  1344805589990453249  aralıksaatdayeniyılımızıkutlayanbirisiyineolma...   \n",
       "\n",
       "                 date month seasons  days  \\\n",
       "0 2021-01-01 03:10:03  Ocak     Kış  Cuma   \n",
       "1 2021-01-01 03:16:07  Ocak     Kış  Cuma   \n",
       "2 2021-01-01 03:17:37  Ocak     Kış  Cuma   \n",
       "3 2021-01-01 03:21:06  Ocak     Kış  Cuma   \n",
       "4 2021-01-01 03:40:12  Ocak     Kış  Cuma   \n",
       "\n",
       "                                         tweet_token  \n",
       "0  [kardesim, sevdigi, cocuga, da, ilan, ask, etm...  \n",
       "1  [bu, yılbaşı, da, saat, tam, da, swni, seviyor...  \n",
       "2  [tam, da, naptınız, ben, her, yıl, tam, bu, va...  \n",
       "3  [da, havai, fişek, gösterisi, yapıldı, tam, di...  \n",
       "4  [aralık, saat, da, yeni, yılımızı, kutlayan, b...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unlabeled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae5eb6e",
   "metadata": {},
   "source": [
    "##### 8. remove stop words from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd3fdf92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acaba',\n",
       " 'ama',\n",
       " 'aslında',\n",
       " 'az',\n",
       " 'bazı',\n",
       " 'belki',\n",
       " 'biri',\n",
       " 'birkaç',\n",
       " 'birşey',\n",
       " 'biz',\n",
       " 'bu',\n",
       " 'da',\n",
       " 'daha',\n",
       " 'de',\n",
       " 'defa',\n",
       " 'diye',\n",
       " 'en',\n",
       " 'eğer',\n",
       " 'gibi',\n",
       " 'hem',\n",
       " 'hep',\n",
       " 'hepsi',\n",
       " 'her',\n",
       " 'hiç',\n",
       " 'ile',\n",
       " 'ise',\n",
       " 'için',\n",
       " 'kez',\n",
       " 'ki',\n",
       " 'kim',\n",
       " 'mu',\n",
       " 'mü',\n",
       " 'mı',\n",
       " 'nasıl',\n",
       " 'ne',\n",
       " 'neden',\n",
       " 'nerde',\n",
       " 'nerede',\n",
       " 'nereye',\n",
       " 'niye',\n",
       " 'niçin',\n",
       " 'o',\n",
       " 'sanki',\n",
       " 'siz',\n",
       " 'tüm',\n",
       " 've',\n",
       " 'veya',\n",
       " 'ya',\n",
       " 'yani',\n",
       " 'çok',\n",
       " 'çünkü',\n",
       " 'şey',\n",
       " 'şu'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"turkish\"))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f83eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"tweet_token_clean\"] = combined_df[\"tweet_token\"].apply(lambda x: [word for word in x if not word in stop_words])\n",
    "df_unlabeled[\"tweet_token_clean\"] = df_unlabeled[\"tweet_token\"].apply(lambda x: [word for word in x if not word in stop_words])\n",
    "df_labeled[\"tweet_token_clean\"] = df_labeled[\"tweet_token\"].apply(lambda x: [word for word in x if not word in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e938fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>seasons</th>\n",
       "      <th>days</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1344798002490314752</td>\n",
       "      <td>kardesimsevdigicocugadailanasketmiscocuksimdiy...</td>\n",
       "      <td>2021-01-01 03:10:03</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "      <td>[kardesim, sevdigi, cocuga, da, ilan, ask, etm...</td>\n",
       "      <td>[kardesim, sevdigi, cocuga, ilan, ask, etmis, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1344799527673470977</td>\n",
       "      <td>buyılbaşıdasaattamdaswniseviyorummesajıgelmedi</td>\n",
       "      <td>2021-01-01 03:16:07</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "      <td>[bu, yılbaşı, da, saat, tam, da, swni, seviyor...</td>\n",
       "      <td>[yılbaşı, saat, tam, swni, seviyorum, mesajı, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1344799907719348226</td>\n",
       "      <td>tamdanaptınızbenheryıltambuvakitdinlediğimşark...</td>\n",
       "      <td>2021-01-01 03:17:37</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "      <td>[tam, da, naptınız, ben, her, yıl, tam, bu, va...</td>\n",
       "      <td>[tam, naptınız, ben, yıl, tam, vakit, dinlediğ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1344800782802165762</td>\n",
       "      <td>dahavaifişekgösterisiyapıldıtamdibimizdeancakk...</td>\n",
       "      <td>2021-01-01 03:21:06</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "      <td>[da, havai, fişek, gösterisi, yapıldı, tam, di...</td>\n",
       "      <td>[havai, fişek, gösterisi, yapıldı, tam, dibimi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1344805589990453249</td>\n",
       "      <td>aralıksaatdayeniyılımızıkutlayanbirisiyineolma...</td>\n",
       "      <td>2021-01-01 03:40:12</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "      <td>[aralık, saat, da, yeni, yılımızı, kutlayan, b...</td>\n",
       "      <td>[aralık, saat, yeni, yılımızı, kutlayan, biris...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                              tweet  \\\n",
       "0  1344798002490314752  kardesimsevdigicocugadailanasketmiscocuksimdiy...   \n",
       "1  1344799527673470977     buyılbaşıdasaattamdaswniseviyorummesajıgelmedi   \n",
       "2  1344799907719348226  tamdanaptınızbenheryıltambuvakitdinlediğimşark...   \n",
       "3  1344800782802165762  dahavaifişekgösterisiyapıldıtamdibimizdeancakk...   \n",
       "4  1344805589990453249  aralıksaatdayeniyılımızıkutlayanbirisiyineolma...   \n",
       "\n",
       "                 date month seasons  days  \\\n",
       "0 2021-01-01 03:10:03  Ocak     Kış  Cuma   \n",
       "1 2021-01-01 03:16:07  Ocak     Kış  Cuma   \n",
       "2 2021-01-01 03:17:37  Ocak     Kış  Cuma   \n",
       "3 2021-01-01 03:21:06  Ocak     Kış  Cuma   \n",
       "4 2021-01-01 03:40:12  Ocak     Kış  Cuma   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [kardesim, sevdigi, cocuga, da, ilan, ask, etm...   \n",
       "1  [bu, yılbaşı, da, saat, tam, da, swni, seviyor...   \n",
       "2  [tam, da, naptınız, ben, her, yıl, tam, bu, va...   \n",
       "3  [da, havai, fişek, gösterisi, yapıldı, tam, di...   \n",
       "4  [aralık, saat, da, yeni, yılımızı, kutlayan, b...   \n",
       "\n",
       "                                   tweet_token_clean  \n",
       "0  [kardesim, sevdigi, cocuga, ilan, ask, etmis, ...  \n",
       "1  [yılbaşı, saat, tam, swni, seviyorum, mesajı, ...  \n",
       "2  [tam, naptınız, ben, yıl, tam, vakit, dinlediğ...  \n",
       "3  [havai, fişek, gösterisi, yapıldı, tam, dibimi...  \n",
       "4  [aralık, saat, yeni, yılımızı, kutlayan, biris...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unlabeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be98954d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>month</th>\n",
       "      <th>seasons</th>\n",
       "      <th>days</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1606767075984375808</td>\n",
       "      <td>berkalikedimseniçoközledimölmekiçindahaküçücük...</td>\n",
       "      <td>2022-12-24 21:41:37</td>\n",
       "      <td>1</td>\n",
       "      <td>Aralık</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cumartesi</td>\n",
       "      <td>[berk, ali, kedim, seni, çok, özledim, ölmek, ...</td>\n",
       "      <td>[berk, ali, kedim, seni, özledim, ölmek, küçüc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1537178207677448193</td>\n",
       "      <td>yaniöylesineciddiyealacaksınkiyaşamayıyetmişin...</td>\n",
       "      <td>2022-06-15 21:00:18</td>\n",
       "      <td>1</td>\n",
       "      <td>Haziran</td>\n",
       "      <td>Yaz</td>\n",
       "      <td>Çarşamba</td>\n",
       "      <td>[yani, öylesine, ciddiye, alacaksın, ki, yaşam...</td>\n",
       "      <td>[öylesine, ciddiye, alacaksın, yaşamayı, yetmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1536458790802972673</td>\n",
       "      <td>saçlarınıngölgesindeölmeknegüzeldi</td>\n",
       "      <td>2022-06-13 21:21:36</td>\n",
       "      <td>1</td>\n",
       "      <td>Haziran</td>\n",
       "      <td>Yaz</td>\n",
       "      <td>Pazartesi</td>\n",
       "      <td>[saçlarının, gölgesinde, ölmek, ne, güzeldi]</td>\n",
       "      <td>[saçlarının, gölgesinde, ölmek, güzeldi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1495413883166760960</td>\n",
       "      <td>öylegüzelbaktınkigözlerimesevmekdeğilölmekgeld...</td>\n",
       "      <td>2022-02-20 15:03:47</td>\n",
       "      <td>1</td>\n",
       "      <td>Şubat</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Pazar</td>\n",
       "      <td>[öyle, güzel, baktın, ki, gözlerime, sevmek, d...</td>\n",
       "      <td>[öyle, güzel, baktın, gözlerime, sevmek, değil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1490420667614904334</td>\n",
       "      <td>sevmekbiriiçinölmekdeğilherşeyerağmenyaşayabil...</td>\n",
       "      <td>2022-02-06 20:22:32</td>\n",
       "      <td>1</td>\n",
       "      <td>Şubat</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Pazar</td>\n",
       "      <td>[sevmek, biri, için, ölmek, değil, her, şeye, ...</td>\n",
       "      <td>[sevmek, ölmek, değil, şeye, rağmen, yaşayabil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                              tweet  \\\n",
       "0  1606767075984375808  berkalikedimseniçoközledimölmekiçindahaküçücük...   \n",
       "1  1537178207677448193  yaniöylesineciddiyealacaksınkiyaşamayıyetmişin...   \n",
       "2  1536458790802972673                 saçlarınıngölgesindeölmeknegüzeldi   \n",
       "3  1495413883166760960  öylegüzelbaktınkigözlerimesevmekdeğilölmekgeld...   \n",
       "4  1490420667614904334  sevmekbiriiçinölmekdeğilherşeyerağmenyaşayabil...   \n",
       "\n",
       "                 date  label    month seasons       days  \\\n",
       "0 2022-12-24 21:41:37      1   Aralık     Kış  Cumartesi   \n",
       "1 2022-06-15 21:00:18      1  Haziran     Yaz   Çarşamba   \n",
       "2 2022-06-13 21:21:36      1  Haziran     Yaz  Pazartesi   \n",
       "3 2022-02-20 15:03:47      1    Şubat     Kış      Pazar   \n",
       "4 2022-02-06 20:22:32      1    Şubat     Kış      Pazar   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [berk, ali, kedim, seni, çok, özledim, ölmek, ...   \n",
       "1  [yani, öylesine, ciddiye, alacaksın, ki, yaşam...   \n",
       "2       [saçlarının, gölgesinde, ölmek, ne, güzeldi]   \n",
       "3  [öyle, güzel, baktın, ki, gözlerime, sevmek, d...   \n",
       "4  [sevmek, biri, için, ölmek, değil, her, şeye, ...   \n",
       "\n",
       "                                   tweet_token_clean  \n",
       "0  [berk, ali, kedim, seni, özledim, ölmek, küçüc...  \n",
       "1  [öylesine, ciddiye, alacaksın, yaşamayı, yetmi...  \n",
       "2           [saçlarının, gölgesinde, ölmek, güzeldi]  \n",
       "3  [öyle, güzel, baktın, gözlerime, sevmek, değil...  \n",
       "4  [sevmek, ölmek, değil, şeye, rağmen, yaşayabil...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de41c8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>seasons</th>\n",
       "      <th>days</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1344798002490314752</td>\n",
       "      <td>kardesimsevdigicocugadailanasketmiscocuksimdiy...</td>\n",
       "      <td>2021-01-01 03:10:03</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[kardesim, sevdigi, cocuga, da, ilan, ask, etm...</td>\n",
       "      <td>[kardesim, sevdigi, cocuga, ilan, ask, etmis, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1344799527673470977</td>\n",
       "      <td>buyılbaşıdasaattamdaswniseviyorummesajıgelmedi</td>\n",
       "      <td>2021-01-01 03:16:07</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[bu, yılbaşı, da, saat, tam, da, swni, seviyor...</td>\n",
       "      <td>[yılbaşı, saat, tam, swni, seviyorum, mesajı, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1344799907719348226</td>\n",
       "      <td>tamdanaptınızbenheryıltambuvakitdinlediğimşark...</td>\n",
       "      <td>2021-01-01 03:17:37</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[tam, da, naptınız, ben, her, yıl, tam, bu, va...</td>\n",
       "      <td>[tam, naptınız, ben, yıl, tam, vakit, dinlediğ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1344800782802165762</td>\n",
       "      <td>dahavaifişekgösterisiyapıldıtamdibimizdeancakk...</td>\n",
       "      <td>2021-01-01 03:21:06</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[da, havai, fişek, gösterisi, yapıldı, tam, di...</td>\n",
       "      <td>[havai, fişek, gösterisi, yapıldı, tam, dibimi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1344805589990453249</td>\n",
       "      <td>aralıksaatdayeniyılımızıkutlayanbirisiyineolma...</td>\n",
       "      <td>2021-01-01 03:40:12</td>\n",
       "      <td>Ocak</td>\n",
       "      <td>Kış</td>\n",
       "      <td>Cuma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[aralık, saat, da, yeni, yılımızı, kutlayan, b...</td>\n",
       "      <td>[aralık, saat, yeni, yılımızı, kutlayan, biris...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                              tweet  \\\n",
       "0  1344798002490314752  kardesimsevdigicocugadailanasketmiscocuksimdiy...   \n",
       "1  1344799527673470977     buyılbaşıdasaattamdaswniseviyorummesajıgelmedi   \n",
       "2  1344799907719348226  tamdanaptınızbenheryıltambuvakitdinlediğimşark...   \n",
       "3  1344800782802165762  dahavaifişekgösterisiyapıldıtamdibimizdeancakk...   \n",
       "4  1344805589990453249  aralıksaatdayeniyılımızıkutlayanbirisiyineolma...   \n",
       "\n",
       "                 date month seasons  days  label  \\\n",
       "0 2021-01-01 03:10:03  Ocak     Kış  Cuma    NaN   \n",
       "1 2021-01-01 03:16:07  Ocak     Kış  Cuma    NaN   \n",
       "2 2021-01-01 03:17:37  Ocak     Kış  Cuma    NaN   \n",
       "3 2021-01-01 03:21:06  Ocak     Kış  Cuma    NaN   \n",
       "4 2021-01-01 03:40:12  Ocak     Kış  Cuma    NaN   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [kardesim, sevdigi, cocuga, da, ilan, ask, etm...   \n",
       "1  [bu, yılbaşı, da, saat, tam, da, swni, seviyor...   \n",
       "2  [tam, da, naptınız, ben, her, yıl, tam, bu, va...   \n",
       "3  [da, havai, fişek, gösterisi, yapıldı, tam, di...   \n",
       "4  [aralık, saat, da, yeni, yılımızı, kutlayan, b...   \n",
       "\n",
       "                                   tweet_token_clean  \n",
       "0  [kardesim, sevdigi, cocuga, ilan, ask, etmis, ...  \n",
       "1  [yılbaşı, saat, tam, swni, seviyorum, mesajı, ...  \n",
       "2  [tam, naptınız, ben, yıl, tam, vakit, dinlediğ...  \n",
       "3  [havai, fişek, gösterisi, yapıldı, tam, dibimi...  \n",
       "4  [aralık, saat, yeni, yılımızı, kutlayan, biris...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268e9e18",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d21dfc",
   "metadata": {},
   "source": [
    "In here we do an EDA which will give us insights about our data and will help us to decide if we do it for a client (this part is not eligible for this project) and see the patterns. In here we asked a few questions then we answered them driven from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e66ea40",
   "metadata": {},
   "source": [
    "### Questions\n",
    "1. What is the distribution of labels?\n",
    "2. What are the most common words/phrases used in tweets?\n",
    "3. What is the average length of the tweets?\n",
    "4. Is there a correlation between the length of the tweet's label?\n",
    "5. What are the most frequent words?\n",
    "6. What is the most tweet posted month of the year?\n",
    "7. How does the distribution of labels vary over time (date)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d352d657",
   "metadata": {},
   "source": [
    "#### 1. What is the ratio of the positive negative and natural tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61a55ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = df_labeled.loc[df_labeled[\"label\"] == 1].count()[0]\n",
    "notr = df_labeled.loc[df_labeled[\"label\"] == 0].count()[0]\n",
    "negative = df_labeled.loc[df_labeled[\"label\"] == -1].count()[0]\n",
    "\n",
    "labels_r = [\"Positive\",\"Notr\",\"Negative\"]\n",
    "\n",
    "plt.figure(figsize=(8,5),dpi = 100)\n",
    "plt.pie([positive,notr,negative],labels = labels_r,autopct=\"%.f%%\")\n",
    "plt.title(\"Etiket Oranları\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d69788",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = df_labeled[\"label\"].value_counts().sort_index().plot(kind = \"bar\",title = \"Etiket Oranları\",figsize = (8,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef83594b",
   "metadata": {},
   "source": [
    "#### 2. What are the most common words/phrases used in tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec8d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [word for sublist in df_unlabeled[\"tweet_token\"] for word in sublist]\n",
    "all_words_str = ' '.join(all_words)\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words_str)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042f6707",
   "metadata": {},
   "source": [
    "#### 3. What is the average length of the tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ecedab",
   "metadata": {},
   "outputs": [],
   "source": [
    "avr_len = df_unlabeled[\"tweet\"].apply(lambda x: len(x))\n",
    "avr_len.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695aefdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,5),dpi = 100)\n",
    "\n",
    "plt.hist(avr_len,bins = 20,color = \"#731873\",edgecolor = \"k\",log = True)\n",
    "plt.axvline(avr_len.mean(),color = \"r\",label = \"Mean Lenght\",linewidth = 2)\n",
    "\n",
    "plt.title(\"Histogram of Lenghts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43e4580",
   "metadata": {},
   "source": [
    "#### 4. Is there a correlation between the length of the tweet's label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d01db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = df_labeled.copy()\n",
    "train_len[\"len\"] = df_unlabeled[\"tweet\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18aa5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation coefficiency\n",
    "correlation = np.corrcoef(train_len[\"len\"], train_len[\"label\"])[0, 1]\n",
    "\n",
    "plt.figure(figsize=(8, 5), dpi=100)\n",
    "plt.scatter(train_len[\"len\"], train_len[\"label\"])\n",
    "plt.title(\"Text Length vs. Reliability Label\")\n",
    "plt.xlabel(\"Text Length\")\n",
    "plt.ylabel(\"Reliability Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078519d7",
   "metadata": {},
   "source": [
    "#### 5. What are the most frequent words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbd0132",
   "metadata": {},
   "outputs": [],
   "source": [
    "frq = \" \".join([word for sublist in df_unlabeled[\"tweet_token\"] for word in sublist])\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words_str)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45034b8d",
   "metadata": {},
   "source": [
    "Another way to do it\n",
    "\n",
    "all_words = [word for sublist in df_unlabeled[\"tweet_token\"] for word in sublist]\n",
    "all_words_str = ' '.join(all_words)\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words_str)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb7bf5",
   "metadata": {},
   "source": [
    "#### 6. What is the most tweet posted month of the year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa67265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month = df_unlabeled.copy()\n",
    "df_month = df_unlabeled.groupby('month').size().reset_index(name='count')\n",
    "df_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b7716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.style.use(\"fivethirtyeight\")\n",
    "plt.bar(df_month[\"month\"],df_month[\"count\"])\n",
    "\n",
    "plt.xticks(df_month[\"month\"],rotation = 45, ha = \"right\")\n",
    "plt.title(\"En Çok Tweet Atılan Ay\")\n",
    "plt.xlabel(\"Aylar\")\n",
    "plt.ylabel(\"Atılan Tweet Sayısı\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c05b3",
   "metadata": {},
   "source": [
    "#### 7. How does the distribution of labels vary over time (date)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728dbd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_distribution = df_labeled.groupby(\"date\")[\"label\"].value_counts(normalize=True).unstack().fillna(0)\n",
    "\n",
    "label_distribution.plot.area(stacked = True, figsize = (10, 6))\n",
    "plt.title(\"Label Distribution Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Proportion of Tweets\")\n",
    "plt.legend(title = \"Labels\", loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e90b39",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdaf6fb",
   "metadata": {},
   "source": [
    "Now in this part we will vectorize (process to turn words into vectors or rather numbers numbers because computer does not understand the words) our words then we will procced to build our ML algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b109ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cce5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_labeled[\"tweet_token_clean\"].apply(' '.join)\n",
    "y = df_labeled[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8e5b134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_df, y_df = train_test_split(df_labeled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2589e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=5,\n",
    "                             max_df=0.8,\n",
    "                             sublinear_tf=True,\n",
    "                             use_idf=True,\n",
    "                             ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3cb3b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = [' '.join(tokens) for tokens in df_labeled[\"tweet_token_clean\"]]\n",
    "test_texts = [' '.join(tokens) for tokens in df_unlabeled[\"tweet_token_clean\"]]\n",
    "\n",
    "train_vectors = vectorizer.fit_transform(train_texts)\n",
    "test_vectors = vectorizer.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe0c914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2389c288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa4aea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79782c3b",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae51c2f",
   "metadata": {},
   "source": [
    "SVM is a supervised machine learning algorithm used for classification tasks. It works by finding the optimal hyperplane that best separates the classes in the feature space. SVM aims to maximize the margin between the classes, which helps in generalization to unseen data. It is effective in high-dimensional spaces and can handle both linear and non-linear classification tasks through the use of different kernel functions. For this project we will use linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "528001af",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel=\"linear\")\n",
    "t0_svm = time.time()\n",
    "svm.fit(train_vectors,df_labeled[\"label\"])\n",
    "t1_svm = time.time()\n",
    "predict_svm = svm.predict(test_vectors)\n",
    "t2_svm = time.time()\n",
    "\n",
    "time_train_svm = t1_svm - t0_svm\n",
    "time_predic_svm = t2_svm - t1_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82fbdc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time : 11.4763\n",
      "Prediction Time : 8.2869\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [12959, 13272]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Time : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_train_svm\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction Time : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_predic_svm\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m report \u001b[38;5;241m=\u001b[39m classification_report(df_labeled[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m], predict_svm, output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m class_1_metrics \u001b[38;5;241m=\u001b[39m report[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      5\u001b[0m class_0_metrics \u001b[38;5;241m=\u001b[39m report[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2539\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2405\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   2406\u001b[0m     {\n\u001b[0;32m   2407\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2430\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2431\u001b[0m ):\n\u001b[0;32m   2432\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[0;32m   2433\u001b[0m \n\u001b[0;32m   2434\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2536\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[0;32m   2537\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2539\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   2541\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2542\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    407\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    412\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [12959, 13272]"
     ]
    }
   ],
   "source": [
    "print(f\"Training Time : {time_train_svm:.4f}\")\n",
    "print(f\"Prediction Time : {time_predic_svm:.4f}\")\n",
    "report = classification_report(df_labeled[\"label\"], predict_svm, output_dict=True)\n",
    "class_1_metrics = report[\"1\"]\n",
    "class_0_metrics = report[\"0\"]\n",
    "class_n_metrics = report[\"-1\"]\n",
    "print(f\"Metrics for Class 1: {class_1_metrics}\")\n",
    "print(f\"Metrics for Class 0: {class_0_metrics}\")\n",
    "print(f\"Metrics for Class -1: {class_n_metrics}\")\n",
    "\n",
    "\n",
    "accuracy_svm = accuracy_score(df_labeled[\"label\"], predict_svm)\n",
    "f1_score_svm = classification_report(df_labeled[\"label\"], predict_svm, output_dict=True)[\"macro avg\"][\"f1-score\"]\n",
    "print(f\"Accuracy: {accuracy_svm:.4f}\")\n",
    "print(f\"F1 Score: {f1_score_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef28357",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df_labeled[\"label\"], predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff3de2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data = pd.DataFrame({\n",
    "    \"Training Time\": [time_train],\n",
    "    \"Prediction Time\": [time_predic]\n",
    "})\n",
    "\n",
    "sns.heatmap(time_data, annot=True, cmap=\"YlGnBu\", fmt=\".3f\")\n",
    "plt.title(\"SVM Training and Prediction Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca432db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r'[^a-zA-ZğüşıöçĞÜŞİÖÇ\\s]', ' ', text)\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "\n",
    "    stop_words = set(stopwords.words(\"turkish\"))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    \n",
    "    cleaned_text = \" \".join(tokens)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "print(\"please input a text to label\")\n",
    "text_svm = input()\n",
    "cleaned_svm = cleaning_text(text_svm)\n",
    "vectorized_svm = vectorizer.transform([cleaned_svm])\n",
    "predict_svm = svm.predict(vectorized_svm)\n",
    "print(f\"Predicted Label : {predict_svm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c579f5",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8345651d",
   "metadata": {},
   "source": [
    "Random Forest is an ensemble learning method used for classification and regression tasks. It works by constructing multiple decision trees during training and outputting the mode of the classes (for classification) or the mean prediction (for regression) of the individual trees. Random Forest introduces randomness in the construction of each decision tree, both in terms of the data samples used for training and the features considered at each split. This randomness helps to reduce overfitting and improve the model's performance on unseen data. Random Forest is known for its robustness and ability to handle high-dimensional data with ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d90d427",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "t3 = time.time()\n",
    "rf.fit(train_vectors, df_labeled[\"label\"])\n",
    "t4 = time.time()\n",
    "predict_rf = rf.predict(test_vectors)\n",
    "t5 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2d4e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_train_rf = t4 - t3\n",
    "time_predict_rf = t5 - t4\n",
    "print(f\"Training Time : {time_train_rf:.4f}\")\n",
    "print(f\"Prediction Time : {time_predict_rf:.4f}\")\n",
    "report = classification_report(df_labeled[\"label\"], predict_rf, output_dict=True)\n",
    "class_1_metrics = report[\"1\"]\n",
    "class_0_metrics = report[\"0\"]\n",
    "class_n_metrics = report[\"-1\"]\n",
    "print(f\"Metrics for Class 1: {class_1_metrics}\")\n",
    "print(f\"Metrics for Class 0: {class_0_metrics}\")\n",
    "print(f\"Metrics for Class -1: {class_n_metrics}\")\n",
    "\n",
    "\n",
    "\n",
    "accuracy_rf = accuracy_score(df_labeled[\"label\"], predict_rf)\n",
    "f1_score_rf = classification_report(df_labeled[\"label\"], predict_rf, output_dict=True)[\"macro avg\"][\"f1-score\"]\n",
    "\n",
    "print(f\"Accuracy: {accuracy_rf:.4f}\")\n",
    "print(f\"F1 Score: {f1_score_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a411185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data_rf = pd.DataFrame({\n",
    "    \"Training Time\": [time_train_rf],\n",
    "    \"Prediction Time\": [time_predict_rf]\n",
    "})\n",
    "\n",
    "sns.heatmap(time_data_rf, annot=True, cmap=\"YlGnBu\", fmt=\".3f\")\n",
    "plt.title(\"Random Forest Training and Prediction Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567e6f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"please input a text to label\")\n",
    "text_rf = input()\n",
    "cleaned_rf = cleaning_text(text_rf)\n",
    "vectorized_rf = vectorizer.transform([cleaned_rf])\n",
    "predict_rf = rf.predict(vectorized_rf)\n",
    "print(f\"Predicted Label : {predict_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fea58b9",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef477f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f1f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed6c099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0fb676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae8aa537",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0454606f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e5ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75936034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6c97d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b68ed352",
   "metadata": {},
   "source": [
    "## Cleaning Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aea8deb",
   "metadata": {},
   "source": [
    "This fuction does the entire cleaning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec15344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r'[^a-zA-ZğüşıöçĞÜŞİÖÇ\\s]', ' ', text)\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "\n",
    "    stop_words = set(stopwords.words(\"turkish\"))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    \n",
    "    cleaned_text = \" \".join(tokens)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "print(\"please input a text to label\")\n",
    "text_clean = input()\n",
    "print(cleaning_text(text_clean))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
